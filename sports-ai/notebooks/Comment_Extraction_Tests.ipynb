{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d46634",
   "metadata": {},
   "source": [
    "# Comment Extraction Tests: Rule-based, NER, and Hybrid\n",
    "\n",
    "This notebook tests and compares algorithms that extract structured match events from free-text comments (e.g., goals, cards, substitutions). It includes:\n",
    "- Rule-based extraction using regex and spaCy Matcher\n",
    "- Model-based extraction using spaCy NER + gazetteers\n",
    "- A hybrid pipeline with conflict resolution\n",
    "- Evaluation (precision/recall/F1), error analysis, and performance benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4521ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace: c:\\Users\\lnipu\\Projects\\Sports-Analysis\n",
      "Data dir : c:\\Users\\lnipu\\Projects\\Sports-Analysis\\sports-ai\\data\n",
      "Out dir  : c:\\Users\\lnipu\\Projects\\Sports-Analysis\\sports-ai\\share\\extraction_tests\n",
      "Installing spacy...\n",
      "en_core_web_sm not found, using blank English model\n",
      "en_core_web_sm not found, using blank English model\n",
      "spaCy pipeline: []\n",
      "spaCy pipeline: []\n"
     ]
    }
   ],
   "source": [
    "# 1) Configure Environment and Imports\n",
    "import sys, os, json, re, math, time, random, pathlib, subprocess\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optional: spaCy & sklearn (will install if missing)\n",
    "try:\n",
    "    import spacy\n",
    "    from spacy.matcher import Matcher\n",
    "    from spacy.pipeline import EntityRuler\n",
    "except ImportError:\n",
    "    spacy = None\n",
    "    Matcher = None\n",
    "    EntityRuler = None\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import classification_report\n",
    "except ImportError:\n",
    "    classification_report = None\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Paths\n",
    "WS = pathlib.Path.cwd().parents[1] if (pathlib.Path.cwd().name == 'notebooks') else pathlib.Path.cwd()\n",
    "DATA_DIR = WS / 'sports-ai' / 'data'\n",
    "OUT_DIR = WS / 'sports-ai' / 'share' / 'extraction_tests'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Workspace:', WS)\n",
    "print('Data dir :', DATA_DIR)\n",
    "print('Out dir  :', OUT_DIR)\n",
    "\n",
    "# Helper to ensure packages\n",
    "def ensure_package(pkg, import_name=None):\n",
    "    import importlib\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        print(f'Installing {pkg}...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "        return True\n",
    "\n",
    "# Optionally install spaCy small model\n",
    "if spacy is None:\n",
    "    ensure_package('spacy')\n",
    "    import spacy\n",
    "    from spacy.matcher import Matcher\n",
    "    from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Load spaCy model (fallback to blank if missing)\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except Exception:\n",
    "    print('en_core_web_sm not found, using blank English model')\n",
    "    nlp = spacy.blank('en')\n",
    "\n",
    "print('spaCy pipeline:', nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db62c95",
   "metadata": {},
   "source": [
    "## 2) Load and Inspect Comment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1d21ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00:12:34</td>\n",
       "      <td>45' GOAL! Messi scores after a quick one-two. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00:14:10</td>\n",
       "      <td>Yellow card shown to Ramos for a late tackle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>00:17:02</td>\n",
       "      <td>Substitution: F. Valverde ON for L. Modric.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>00:21:41</td>\n",
       "      <td>Red card! The goalkeeper is sent off for handl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>00:26:00</td>\n",
       "      <td>Another substitution: Haaland replaces Alvarez.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>00:29:39</td>\n",
       "      <td>Corner for Real Madrid; well defended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>00:31:15</td>\n",
       "      <td>Offside flagged against Mbappé.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id timestamp                                               text\n",
       "0   1  00:12:34  45' GOAL! Messi scores after a quick one-two. ...\n",
       "1   2  00:14:10      Yellow card shown to Ramos for a late tackle.\n",
       "2   3  00:17:02        Substitution: F. Valverde ON for L. Modric.\n",
       "3   4  00:21:41  Red card! The goalkeeper is sent off for handl...\n",
       "4   5  00:26:00    Another substitution: Haaland replaces Alvarez.\n",
       "5   6  00:29:39             Corner for Real Madrid; well defended.\n",
       "6   7  00:31:15                    Offside flagged against Mbappé."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a small sample comments DataFrame\n",
    "sample_comments = [\n",
    "    {\"id\": 1, \"timestamp\": \"00:12:34\", \"text\": \"45' GOAL! Messi scores after a quick one-two. Barcelona lead 1-0.\"},\n",
    "    {\"id\": 2, \"timestamp\": \"00:14:10\", \"text\": \"Yellow card shown to Ramos for a late tackle.\"},\n",
    "    {\"id\": 3, \"timestamp\": \"00:17:02\", \"text\": \"Substitution: F. Valverde ON for L. Modric.\"},\n",
    "    {\"id\": 4, \"timestamp\": \"00:21:41\", \"text\": \"Red card! The goalkeeper is sent off for handling outside the box.\"},\n",
    "    {\"id\": 5, \"timestamp\": \"00:26:00\", \"text\": \"Another substitution: Haaland replaces Alvarez.\"},\n",
    "    {\"id\": 6, \"timestamp\": \"00:29:39\", \"text\": \"Corner for Real Madrid; well defended.\"},\n",
    "    {\"id\": 7, \"timestamp\": \"00:31:15\", \"text\": \"Offside flagged against Mbappé.\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(sample_comments)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092787d9",
   "metadata": {},
   "source": [
    "## 3) Define Target Schemas and Label Taxonomy\n",
    "We'll extract spans and events with the following labels: `PLAYER`, `TEAM`, `ACTION`, `CARD`, `SUBSTITUTION`, `SCORE`, `TIME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7603ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['PLAYER', 'TEAM', 'ACTION', 'CARD', 'SUBSTITUTION', 'SCORE', 'TIME']\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "LABELS = [\"PLAYER\", \"TEAM\", \"ACTION\", \"CARD\", \"SUBSTITUTION\", \"SCORE\", \"TIME\"]\n",
    "\n",
    "@dataclass\n",
    "class Span:\n",
    "    start: int\n",
    "    end: int\n",
    "    label: str\n",
    "    text: str\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    minute: Optional[str]\n",
    "    type: str\n",
    "    description: str\n",
    "    player_in: Optional[str] = None\n",
    "    player_out: Optional[str] = None\n",
    "    player: Optional[str] = None\n",
    "    team: Optional[str] = None\n",
    "    tags: Optional[List[str]] = None\n",
    "\n",
    "\n",
    "def validate_span(s: Span) -> bool:\n",
    "    return 0 <= s.start < s.end and s.label in LABELS\n",
    "\n",
    "\n",
    "def validate_event(e: Event) -> bool:\n",
    "    return bool(e.type)\n",
    "\n",
    "print('Labels:', LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1072de3",
   "metadata": {},
   "source": [
    "## 4) Text Preprocessing Pipeline\n",
    "Functions to normalize, tokenize, and sentence-split comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f85912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"45' GOAL!\", 'Messi scores after a quick one-two.', 'Barcelona lead 1-0.']\n",
      "['Yellow card shown to Ramos for a late tackle.']\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(s: str) -> str:\n",
    "    s = s.replace('\\u200b', ' ').strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def sentence_split(s: str) -> List[str]:\n",
    "    s = normalize_text(s)\n",
    "    parts = re.split(r\"(?<=[\\.!?])\\s+\", s)\n",
    "    return [p for p in parts if p]\n",
    "\n",
    "\n",
    "def tokenize(s: str) -> List[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", s)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "for t in df['text'].head(2):\n",
    "    print(sentence_split(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7175005",
   "metadata": {},
   "source": [
    "## 5) Gazetteers: Teams and Players\n",
    "Load team and player lists if available; otherwise use a small demo list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18943abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams: {'barcelona', 'real madrid', 'manchester city'}\n",
      "Players: {'erling haaland', 'luka modric', 'federico valverde', 'kylian mbappé', 'julian alvarez', 'lionel messi', 'sergio ramos'}\n"
     ]
    }
   ],
   "source": [
    "# Demo gazetteers; replace with real CSV/JSON as needed\n",
    "teams = {\"barcelona\", \"real madrid\", \"manchester city\"}\n",
    "players = {\"lionel messi\", \"sergio ramos\", \"federico valverde\", \"luka modric\", \"erling haaland\", \"julian alvarez\", \"kylian mbappé\"}\n",
    "\n",
    "# Normalize helper\n",
    "norm = lambda s: re.sub(r\"\\s+\", \" \", s.replace('.', '')).strip().lower()\n",
    "\n",
    "team_set = {norm(t) for t in teams}\n",
    "player_set = {norm(p) for p in players}\n",
    "\n",
    "print('Teams:', team_set)\n",
    "print('Players:', player_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba312fa",
   "metadata": {},
   "source": [
    "## 6) Rule-Based Extraction with Regex and spaCy Matcher\n",
    "We implement regex patterns for scores, time markers, cards, and substitutions. We also add an optional spaCy Matcher for phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf9a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule patterns initialized\n"
     ]
    }
   ],
   "source": [
    "TIME_RE = re.compile(r\"(?:(\\d+)(?:\\+(\\d+))?\\s*')|\\b(?:min(?:ute)?s?)\\b\", re.I)\n",
    "SCORE_RE = re.compile(r\"\\b(\\d{1,2})\\s*[-:]\\s*(\\d{1,2})\\b\")\n",
    "YELLOW_RE = re.compile(r\"\\byellow card\\b|\\bbooked\\b\", re.I)\n",
    "RED_RE = re.compile(r\"\\bred card\\b|\\bsent off\\b\", re.I)\n",
    "GOAL_RE = re.compile(r\"\\bgoal\\b|\\bscor(?:e|ed|es)\\b|\\bpenalty\\b\", re.I)\n",
    "SUB_ON_FOR_RE = re.compile(r\"\\b(.+?)\\s+(?:on|in)\\s+for\\s+(.+?)\\b\", re.I)\n",
    "SUB_REPLACES_RE = re.compile(r\"\\b(.+?)\\s+replaces\\s+(.+?)\\b\", re.I)\n",
    "REPLACED_BY_RE = re.compile(r\"\\b(.+?)\\s+replaced\\s+by\\s+(.+?)\\b\", re.I)\n",
    "\n",
    "\n",
    "def parse_minute(text: str) -> Optional[str]:\n",
    "    m = TIME_RE.search(text)\n",
    "    if not m: return None\n",
    "    if m.group(1):\n",
    "        base = int(m.group(1))\n",
    "        extra = int(m.group(2) or 0)\n",
    "        return f\"{base}+{extra}\" if extra else str(base)\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_tags(text: str) -> List[str]:\n",
    "    t = text.lower()\n",
    "    tags = []\n",
    "    if GOAL_RE.search(t): tags.append('goal')\n",
    "    if YELLOW_RE.search(t): tags.append('yellow card')\n",
    "    if RED_RE.search(t): tags.append('red card')\n",
    "    if SUB_ON_FOR_RE.search(t) or SUB_REPLACES_RE.search(t) or REPLACED_BY_RE.search(t): tags.append('substitution')\n",
    "    if SCORE_RE.search(t): tags.append('score')\n",
    "    return tags\n",
    "\n",
    "\n",
    "def parse_substitution_players(text: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    t = text.strip()\n",
    "    m = SUB_ON_FOR_RE.search(t) or SUB_REPLACES_RE.search(t)\n",
    "    if not m:\n",
    "        m2 = REPLACED_BY_RE.search(t)\n",
    "    else:\n",
    "        m2 = None\n",
    "    if m:\n",
    "        return m.group(1).strip(), m.group(2).strip()\n",
    "    if m2:\n",
    "        return m2.group(2).strip(), m2.group(1).strip()\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Optional spaCy Matcher example (phrase-based for teams/players)\n",
    "matcher = Matcher(nlp.vocab) if hasattr(nlp, 'vocab') else None\n",
    "if matcher is not None and 'ner' in nlp.pipe_names:\n",
    "    # Simple pattern: proper nouns followed by verb like 'scores' could be a GOAL trigger\n",
    "    pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"LOWER\": {\"IN\": [\"scores\", \"scored\"]}}]\n",
    "    try:\n",
    "        matcher.add(\"GOAL_PHRASE\", [pattern])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print('Rule patterns initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69653ff8",
   "metadata": {},
   "source": [
    "## 7) Model-Based Extraction with spaCy NER\n",
    "Run NER, then map model labels to target schema. Optionally add an EntityRuler with gazetteers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f1470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityRuler added with 10 patterns\n"
     ]
    }
   ],
   "source": [
    "# Build an EntityRuler with gazetteers to help NER\n",
    "if 'entity_ruler' not in nlp.pipe_names:\n",
    "    ruler = nlp.add_pipe('entity_ruler')\n",
    "else:\n",
    "    ruler = nlp.get_pipe('entity_ruler')\n",
    "\n",
    "patterns = []\n",
    "for t in team_set:\n",
    "    patterns.append({\"label\": \"ORG\", \"pattern\": t})\n",
    "for p in player_set:\n",
    "    patterns.append({\"label\": \"PERSON\", \"pattern\": p})\n",
    "\n",
    "try:\n",
    "    ruler.add_patterns(patterns)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "ner_label_map = {\"PERSON\": \"PLAYER\", \"ORG\": \"TEAM\"}\n",
    "\n",
    "def spacy_extract_spans(text: str) -> List[Span]:\n",
    "    doc = nlp(text)\n",
    "    spans = []\n",
    "    for ent in doc.ents:\n",
    "        label = ner_label_map.get(ent.label_, None)\n",
    "        if not label:\n",
    "            continue\n",
    "        spans.append(Span(start=ent.start_char, end=ent.end_char, label=label, text=ent.text))\n",
    "    return spans\n",
    "\n",
    "print('EntityRuler added with', len(patterns), 'patterns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682423a",
   "metadata": {},
   "source": [
    "## 8) Hybrid Extraction Pipeline and Conflict Resolution\n",
    "Compose rule-based and model-based outputs. Provide a unified `extract(comment)` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7384d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT: 45' GOAL! Messi scores after a quick one-two. Barcelona lead 1-0.\n",
      "SPANS: [{'start': 0, 'end': 3, 'label': 'TIME', 'text': \"45'\"}, {'start': 4, 'end': 8, 'label': 'ACTION', 'text': 'GOAL'}, {'start': 61, 'end': 64, 'label': 'SCORE', 'text': '1-0'}]\n",
      "EVENT: {'minute': '45', 'type': 'goal', 'description': \"45' GOAL! Messi scores after a quick one-two. Barcelona lead 1-0.\", 'player_in': None, 'player_out': None, 'player': None, 'team': None, 'tags': ['goal', 'score']}\n",
      "\n",
      "TEXT: Yellow card shown to Ramos for a late tackle.\n",
      "SPANS: [{'start': 0, 'end': 11, 'label': 'CARD', 'text': 'Yellow card'}]\n",
      "EVENT: {'minute': None, 'type': 'yellow card', 'description': 'Yellow card shown to Ramos for a late tackle.', 'player_in': None, 'player_out': None, 'player': None, 'team': None, 'tags': ['yellow card']}\n",
      "\n",
      "TEXT: Substitution: F. Valverde ON for L. Modric.\n",
      "SPANS: [{'start': 0, 'end': 34, 'label': 'SUBSTITUTION', 'text': 'Substitution: F. Valverde ON for L'}]\n",
      "EVENT: {'minute': None, 'type': 'substitution', 'description': 'Substitution: F. Valverde ON for L. Modric.', 'player_in': 'Substitution: F. Valverde', 'player_out': 'L', 'player': None, 'team': None, 'tags': ['substitution']}\n",
      "\n",
      "TEXT: Red card! The goalkeeper is sent off for handling outside the box.\n",
      "SPANS: [{'start': 0, 'end': 8, 'label': 'CARD', 'text': 'Red card'}]\n",
      "EVENT: {'minute': None, 'type': 'red card', 'description': 'Red card! The goalkeeper is sent off for handling outside the box.', 'player_in': None, 'player_out': None, 'player': None, 'team': None, 'tags': ['red card']}\n",
      "\n",
      "TEXT: Another substitution: Haaland replaces Alvarez.\n",
      "SPANS: [{'start': 0, 'end': 46, 'label': 'SUBSTITUTION', 'text': 'Another substitution: Haaland replaces Alvarez'}]\n",
      "EVENT: {'minute': None, 'type': 'substitution', 'description': 'Another substitution: Haaland replaces Alvarez.', 'player_in': 'Another substitution: Haaland', 'player_out': 'Alvarez', 'player': None, 'team': None, 'tags': ['substitution']}\n",
      "\n",
      "TEXT: Corner for Real Madrid; well defended.\n",
      "SPANS: []\n",
      "EVENT: None\n",
      "\n",
      "TEXT: Offside flagged against Mbappé.\n",
      "SPANS: []\n",
      "EVENT: None\n"
     ]
    }
   ],
   "source": [
    "def rule_based_extract_spans(text: str) -> List[Span]:\n",
    "    spans: List[Span] = []\n",
    "    # TIME\n",
    "    for m in TIME_RE.finditer(text):\n",
    "        s, e = m.span()\n",
    "        spans.append(Span(s, e, 'TIME', text[s:e]))\n",
    "    # SCORE\n",
    "    for m in SCORE_RE.finditer(text):\n",
    "        s, e = m.span()\n",
    "        spans.append(Span(s, e, 'SCORE', text[s:e]))\n",
    "    # CARDS\n",
    "    if YELLOW_RE.search(text):\n",
    "        s, e = YELLOW_RE.search(text).span()\n",
    "        spans.append(Span(s, e, 'CARD', text[s:e]))\n",
    "    if RED_RE.search(text):\n",
    "        s, e = RED_RE.search(text).span()\n",
    "        spans.append(Span(s, e, 'CARD', text[s:e]))\n",
    "    # ACTION/GOAL\n",
    "    if GOAL_RE.search(text):\n",
    "        s, e = GOAL_RE.search(text).span()\n",
    "        spans.append(Span(s, e, 'ACTION', text[s:e]))\n",
    "    # SUBSTITUTION\n",
    "    m = SUB_ON_FOR_RE.search(text) or SUB_REPLACES_RE.search(text) or REPLACED_BY_RE.search(text)\n",
    "    if m:\n",
    "        s, e = m.span()\n",
    "        spans.append(Span(s, e, 'SUBSTITUTION', text[s:e]))\n",
    "    return spans\n",
    "\n",
    "\n",
    "def merge_spans(spans_a: List[Span], spans_b: List[Span]) -> List[Span]:\n",
    "    out: List[Span] = []\n",
    "    seen = set()\n",
    "    for s in spans_a + spans_b:\n",
    "        key = (s.start, s.end, s.label)\n",
    "        if key in seen: continue\n",
    "        # conflict resolution: prefer longer spans when overlapping\n",
    "        conflict = False\n",
    "        for i, t in enumerate(out):\n",
    "            if not (s.end <= t.start or s.start >= t.end):\n",
    "                # overlap – keep the longer span\n",
    "                if (s.end - s.start) > (t.end - t.start):\n",
    "                    out[i] = s\n",
    "                conflict = True\n",
    "                break\n",
    "        if not conflict:\n",
    "            out.append(s)\n",
    "        seen.add(key)\n",
    "    return sorted(out, key=lambda x: x.start)\n",
    "\n",
    "\n",
    "def extract(text: str) -> Tuple[List[Span], Optional[Event]]:\n",
    "    textN = normalize_text(text)\n",
    "    minute = parse_minute(textN)\n",
    "    tags = detect_tags(textN)\n",
    "    spans_rules = rule_based_extract_spans(textN)\n",
    "    spans_ner = spacy_extract_spans(textN)\n",
    "    spans = merge_spans(spans_rules, spans_ner)\n",
    "\n",
    "    # Derive a coarse event\n",
    "    etype = None\n",
    "    if 'substitution' in tags:\n",
    "        etype = 'substitution'\n",
    "    elif 'red card' in tags:\n",
    "        etype = 'red card'\n",
    "    elif 'yellow card' in tags:\n",
    "        etype = 'yellow card'\n",
    "    elif 'goal' in tags:\n",
    "        etype = 'goal'\n",
    "    elif 'score' in tags:\n",
    "        etype = 'score'\n",
    "\n",
    "    ev = None\n",
    "    if etype:\n",
    "        player_in = player_out = None\n",
    "        if etype == 'substitution':\n",
    "            player_in, player_out = parse_substitution_players(textN)\n",
    "        ev = Event(minute=minute, type=etype, description=textN, player_in=player_in, player_out=player_out, tags=tags)\n",
    "\n",
    "    return spans, ev\n",
    "\n",
    "# Quick demo on sample comments\n",
    "for _, row in df.iterrows():\n",
    "    spans, ev = extract(row['text'])\n",
    "    print('\\nTEXT:', row['text'])\n",
    "    print('SPANS:', [asdict(s) for s in spans])\n",
    "    print('EVENT:', asdict(ev) if ev else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3d831",
   "metadata": {},
   "source": [
    "## 9) Evaluation Dataset Split and Ground Truth Loader\n",
    "For this demo, we will generate a tiny labeled subset. Replace with real annotations when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: {'train': [2, 4, 5, 3], 'val': [7, 1], 'test': [6]}\n"
     ]
    }
   ],
   "source": [
    "# Tiny ground truth (for demo).\n",
    "# Format: id -> {type, minute, player_in, player_out}\n",
    "GT = {\n",
    "    1: {\"type\": \"goal\"},\n",
    "    2: {\"type\": \"yellow card\"},\n",
    "    3: {\"type\": \"substitution\", \"player_in\": \"F. Valverde\", \"player_out\": \"L. Modric\"},\n",
    "    4: {\"type\": \"red card\"},\n",
    "}\n",
    "\n",
    "# Train/Val/Test split (toy)\n",
    "ids = df['id'].tolist()\n",
    "random.shuffle(ids)\n",
    "train_ids = ids[:4]\n",
    "val_ids = ids[4:6]\n",
    "test_ids = ids[6:]\n",
    "print('Splits:', {'train': train_ids, 'val': val_ids, 'test': test_ids})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69210fc4",
   "metadata": {},
   "source": [
    "## 10) Evaluate Extraction Quality (P/R/F1)\n",
    "Compute simple event-type accuracy and show a small report. Replace with span-level metrics as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240b602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts true: Counter({'none': 3, 'goal': 1, 'yellow card': 1, 'substitution': 1, 'red card': 1})\n",
      "Counts pred: Counter({'substitution': 2, 'none': 2, 'goal': 1, 'yellow card': 1, 'red card': 1})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        goal       1.00      1.00      1.00         1\n",
      "        none       1.00      0.67      0.80         3\n",
      "    red card       1.00      1.00      1.00         1\n",
      "substitution       0.50      1.00      0.67         1\n",
      " yellow card       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.90      0.93      0.89         7\n",
      "weighted avg       0.93      0.86      0.87         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = [], []\n",
    "for _, row in df[df['id'].isin(train_ids + val_ids + test_ids)].iterrows():\n",
    "    gt = GT.get(row['id'])\n",
    "    spans, ev = extract(row['text'])\n",
    "    y_true.append(gt['type'] if gt else 'none')\n",
    "    y_pred.append(ev.type if ev else 'none')\n",
    "\n",
    "from collections import Counter\n",
    "print('Counts true:', Counter(y_true))\n",
    "print('Counts pred:', Counter(y_pred))\n",
    "\n",
    "if classification_report:\n",
    "    from sklearn.metrics import classification_report as _cr\n",
    "    print(_cr(y_true, y_pred))\n",
    "else:\n",
    "    # Simple accuracy\n",
    "    acc = np.mean([a == b for a, b in zip(y_true, y_pred)])\n",
    "    print('Accuracy:', round(acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e3b6c",
   "metadata": {},
   "source": [
    "## 11) Error Analysis: FP/FN Drill-down\n",
    "Show mismatches and save to CSV for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0597fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gt_type</th>\n",
       "      <th>pred_type</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Another substitution: Haaland replaces Alvarez.</td>\n",
       "      <td>None</td>\n",
       "      <td>substitution</td>\n",
       "      <td>[{'start': 0, 'end': 46, 'label': 'SUBSTITUTIO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             text gt_type     pred_type  \\\n",
       "0   5  Another substitution: Haaland replaces Alvarez.    None  substitution   \n",
       "\n",
       "                                               spans  \n",
       "0  [{'start': 0, 'end': 46, 'label': 'SUBSTITUTIO...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    gt = GT.get(row['id'], {}).get('type')\n",
    "    spans, ev = extract(row['text'])\n",
    "    pred = ev.type if ev else None\n",
    "    if gt != pred:\n",
    "        rows.append({\n",
    "            'id': row['id'],\n",
    "            'text': row['text'],\n",
    "            'gt_type': gt,\n",
    "            'pred_type': pred,\n",
    "            'spans': [asdict(s) for s in spans]\n",
    "        })\n",
    "\n",
    "err_df = pd.DataFrame(rows)\n",
    "err_df.to_csv(OUT_DIR / 'errors.csv', index=False)\n",
    "err_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f042cf8",
   "metadata": {},
   "source": [
    "## 12) Parameter Tuning and Ablation Experiments\n",
    "Toggle regex/NER/gazetteers and compare metrics across configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ffcfab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules only: {'goal': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'none': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3.0}, 'red card': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'substitution': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1.0}, 'yellow card': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'accuracy': 0.8571428571428571, 'macro avg': {'precision': 0.9, 'recall': 0.9333333333333332, 'f1-score': 0.8933333333333333, 'support': 7.0}, 'weighted avg': {'precision': 0.9285714285714286, 'recall': 0.8571428571428571, 'f1-score': 0.8666666666666668, 'support': 7.0}}\n",
      "NER only  : {'goal': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, 'none': {'precision': 0.42857142857142855, 'recall': 1.0, 'f1-score': 0.6, 'support': 3.0}, 'red card': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, 'substitution': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, 'yellow card': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, 'accuracy': 0.42857142857142855, 'macro avg': {'precision': 0.08571428571428572, 'recall': 0.2, 'f1-score': 0.12, 'support': 7.0}, 'weighted avg': {'precision': 0.18367346938775508, 'recall': 0.42857142857142855, 'f1-score': 0.2571428571428571, 'support': 7.0}}\n",
      "Hybrid    : {'goal': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'none': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3.0}, 'red card': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'substitution': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1.0}, 'yellow card': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, 'accuracy': 0.8571428571428571, 'macro avg': {'precision': 0.9, 'recall': 0.9333333333333332, 'f1-score': 0.8933333333333333, 'support': 7.0}, 'weighted avg': {'precision': 0.9285714285714286, 'recall': 0.8571428571428571, 'f1-score': 0.8666666666666668, 'support': 7.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lnipu\\Projects\\Sports-Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\lnipu\\Projects\\Sports-Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\lnipu\\Projects\\Sports-Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "def evaluate_config(use_rules=True, use_ner=True):\n",
    "    y_true, y_pred = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        text = normalize_text(row['text'])\n",
    "        gt = GT.get(row['id'])\n",
    "        minute = parse_minute(text)\n",
    "        tags = detect_tags(text)\n",
    "        spans_rules = rule_based_extract_spans(text) if use_rules else []\n",
    "        spans_ner = spacy_extract_spans(text) if use_ner else []\n",
    "        spans = merge_spans(spans_rules, spans_ner)\n",
    "        etype = None\n",
    "        if 'substitution' in (tags if use_rules else []):\n",
    "            etype = 'substitution'\n",
    "        elif 'red card' in (tags if use_rules else []):\n",
    "            etype = 'red card'\n",
    "        elif 'yellow card' in (tags if use_rules else []):\n",
    "            etype = 'yellow card'\n",
    "        elif 'goal' in (tags if use_rules else []):\n",
    "            etype = 'goal'\n",
    "        elif 'score' in (tags if use_rules else []):\n",
    "            etype = 'score'\n",
    "        y_true.append(gt['type'] if gt else 'none')\n",
    "        y_pred.append(etype or 'none')\n",
    "    if classification_report:\n",
    "        from sklearn.metrics import classification_report as _cr\n",
    "        return _cr(y_true, y_pred, output_dict=True)\n",
    "    else:\n",
    "        acc = np.mean([a == b for a, b in zip(y_true, y_pred)])\n",
    "        return {'accuracy': float(acc)}\n",
    "\n",
    "print('Rules only:', evaluate_config(use_rules=True, use_ner=False))\n",
    "print('NER only  :', evaluate_config(use_rules=False, use_ner=True))\n",
    "print('Hybrid    :', evaluate_config(use_rules=True, use_ner=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f3520",
   "metadata": {},
   "source": [
    "## 13) Performance Benchmarking\n",
    "Measure throughput on a larger synthetic set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9b76ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 7079.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2000 comments in 0.29s; 6876.8 comments/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "big = df.sample(n=len(df), replace=True, random_state=42)\n",
    "N = 2000\n",
    "big = pd.concat([big]* (N // len(df) + 1)).head(N).reset_index(drop=True)\n",
    "\n",
    "start = perf_counter()\n",
    "for t in tqdm(big['text'], total=len(big)):\n",
    "    extract(t)\n",
    "sec = perf_counter() - start\n",
    "print(f\"Processed {len(big)} comments in {sec:.2f}s; {(len(big)/sec):.1f} comments/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d312d6",
   "metadata": {},
   "source": [
    "## 14) Persist Outputs and Export\n",
    "Write extracted events to JSONL for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260678eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote c:\\Users\\lnipu\\Projects\\Sports-Analysis\\sports-ai\\share\\extraction_tests\\extracted_events.jsonl\n"
     ]
    }
   ],
   "source": [
    "# out_path = OUT_DIR / 'extracted_events.jsonl'\n",
    "# with open(out_path, 'w', encoding='utf-8') as f:\n",
    "#     for _, row in df.iterrows():\n",
    "#         spans, ev = extract(row['text'])\n",
    "#         rec = {\n",
    "#             'id': int(row['id']),\n",
    "#             'text': row['text'],\n",
    "#             'spans': [asdict(s) for s in spans],\n",
    "#             'event': (asdict(ev) if ev else None)\n",
    "#         }\n",
    "#         f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "# print('Wrote', out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
